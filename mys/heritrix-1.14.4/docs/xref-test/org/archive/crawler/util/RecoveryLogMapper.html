<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" /><title>RecoveryLogMapper xref</title>
<link type="text/css" rel="stylesheet" href="../../../../stylesheet.css" />
</head>
<body>
<pre>

<a name="1" href="#1">1</a>   <em class="comment">/*<em class="comment"> RecoveryLogMapper.java</em></em>
<a name="2" href="#2">2</a>   <em class="comment">*</em>
<a name="3" href="#3">3</a>   <em class="comment">* $Id: RecoveryLogMapper.java 4647 2006-09-22 18:39:39Z paul_jack $</em>
<a name="4" href="#4">4</a>   <em class="comment">*</em>
<a name="5" href="#5">5</a>   <em class="comment">* Created on Mar 7, 2005</em>
<a name="6" href="#6">6</a>   <em class="comment">*</em>
<a name="7" href="#7">7</a>   <em class="comment">* Copyright (C) 2005 Mike Schwartz.</em>
<a name="8" href="#8">8</a>   <em class="comment">*</em>
<a name="9" href="#9">9</a>   <em class="comment">* This file is part of the Heritrix web crawler (crawler.archive.org).</em>
<a name="10" href="#10">10</a>  <em class="comment">*</em>
<a name="11" href="#11">11</a>  <em class="comment">* Heritrix is free software; you can redistribute it and/or modify</em>
<a name="12" href="#12">12</a>  <em class="comment">* it under the terms of the GNU Lesser Public License as published by</em>
<a name="13" href="#13">13</a>  <em class="comment">* the Free Software Foundation; either version 2.1 of the License, or</em>
<a name="14" href="#14">14</a>  <em class="comment">* any later version.</em>
<a name="15" href="#15">15</a>  <em class="comment">*</em>
<a name="16" href="#16">16</a>  <em class="comment">* Heritrix is distributed in the hope that it will be useful,</em>
<a name="17" href="#17">17</a>  <em class="comment">* but WITHOUT ANY WARRANTY; without even the implied warranty of</em>
<a name="18" href="#18">18</a>  <em class="comment">* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</em>
<a name="19" href="#19">19</a>  <em class="comment">* GNU Lesser Public License for more details.</em>
<a name="20" href="#20">20</a>  <em class="comment">*</em>
<a name="21" href="#21">21</a>  <em class="comment">* You should have received a copy of the GNU Lesser Public License</em>
<a name="22" href="#22">22</a>  <em class="comment">* along with Heritrix; if not, write to the Free Software</em>
<a name="23" href="#23">23</a>  <em class="comment">* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA</em>
<a name="24" href="#24">24</a>  <em class="comment">*/</em>
<a name="25" href="#25">25</a>  
<a name="26" href="#26">26</a>  <em>/**<em>*</em></em>
<a name="27" href="#27">27</a>  <em> * Parses a Heritrix recovery log file (recover.gz), and builds maps</em>
<a name="28" href="#28">28</a>  <em> * that allow a caller to look up any seed URL and get back an Iterator of all</em>
<a name="29" href="#29">29</a>  <em> * URLs successfully crawled from given seed.</em>
<a name="30" href="#30">30</a>  <em> *</em>
<a name="31" href="#31">31</a>  <em> * Also allows lookup on any crawled</em>
<a name="32" href="#32">32</a>  <em> * URL to find the seed URL from which the crawler reached that URL (through 1</em>
<a name="33" href="#33">33</a>  <em> * or more discovered URL hops, which are collapsed in this lookup).</em>
<a name="34" href="#34">34</a>  <em> * </em>
<a name="35" href="#35">35</a>  <em> * &lt;p>This code creates some fairly large collections (proprotionate in size to</em>
<a name="36" href="#36">36</a>  <em> * # discovered URLs) so make sure you allocate</em>
<a name="37" href="#37">37</a>  <em> * it a large heap to work in. It also takes a while to process a recover log.</em>
<a name="38" href="#38">38</a>  <em> * &lt;p>See {@link #main()} method at end for test/demo code.</em>
<a name="39" href="#39">39</a>  <em> * @author Mike Schwartz, schwartz at CodeOnTheRoad dot com</em>
<a name="40" href="#40">40</a>  <em> */</em>
<a name="41" href="#41">41</a>  <strong>package</strong> <a href="../../../../org/archive/crawler/util/package-summary.html">org.archive.crawler.util</a>;
<a name="42" href="#42">42</a>  
<a name="43" href="#43">43</a>  <strong>import</strong> org.archive.crawler.frontier.RecoveryJournal;
<a name="44" href="#44">44</a>  
<a name="45" href="#45">45</a>  <strong>import</strong> java.io.File;
<a name="46" href="#46">46</a>  <strong>import</strong> java.io.LineNumberReader;
<a name="47" href="#47">47</a>  <strong>import</strong> java.io.PrintWriter;
<a name="48" href="#48">48</a>  <strong>import</strong> java.io.FileOutputStream;
<a name="49" href="#49">49</a>  <strong>import</strong> java.util.Collection;
<a name="50" href="#50">50</a>  <strong>import</strong> java.util.HashMap;
<a name="51" href="#51">51</a>  <strong>import</strong> java.util.HashSet;
<a name="52" href="#52">52</a>  <strong>import</strong> java.util.Iterator;
<a name="53" href="#53">53</a>  <strong>import</strong> java.util.Map;
<a name="54" href="#54">54</a>  <strong>import</strong> java.util.Set;
<a name="55" href="#55">55</a>  <strong>import</strong> java.util.logging.Level;
<a name="56" href="#56">56</a>  <strong>import</strong> java.util.logging.Logger;
<a name="57" href="#57">57</a>  
<a name="58" href="#58">58</a>  <strong>public</strong> <strong>class</strong> <a href="../../../../org/archive/crawler/util/RecoveryLogMapper.html">RecoveryLogMapper</a> {
<a name="59" href="#59">59</a>      <strong>private</strong> <strong>static</strong> <strong>final</strong> <strong>char</strong> LOG_LINE_START_CHAR =
<a name="60" href="#60">60</a>          RecoveryJournal.F_ADD.charAt(0);
<a name="61" href="#61">61</a>      <strong>private</strong> <strong>static</strong> <strong>final</strong> Logger logger =
<a name="62" href="#62">62</a>          Logger.getLogger(RecoveryLogMapper.<strong>class</strong>.getName());
<a name="63" href="#63">63</a>      <strong>private</strong> PrintWriter seedNotFoundPrintWriter = <strong>null</strong>;
<a name="64" href="#64">64</a>  
<a name="65" href="#65">65</a>      <em>/**<em>*</em></em>
<a name="66" href="#66">66</a>  <em>     * Tracks seed for each crawled URL</em>
<a name="67" href="#67">67</a>  <em>     */</em>
<a name="68" href="#68">68</a>      <strong>private</strong> Map&lt;String,String> crawledUrlToSeedMap
<a name="69" href="#69">69</a>       = <strong>new</strong> HashMap&lt;String,String>();
<a name="70" href="#70">70</a>  
<a name="71" href="#71">71</a>      <em>/**<em>*</em></em>
<a name="72" href="#72">72</a>  <em>     * Maps seed URLs to Set of discovered URLs</em>
<a name="73" href="#73">73</a>  <em>     */</em>
<a name="74" href="#74">74</a>      <strong>private</strong> Map&lt;String,Set&lt;String>> seedUrlToDiscoveredUrlsMap
<a name="75" href="#75">75</a>       = <strong>new</strong> HashMap&lt;String,Set&lt;String>>();
<a name="76" href="#76">76</a>  
<a name="77" href="#77">77</a>      <em>/**<em>*</em></em>
<a name="78" href="#78">78</a>  <em>     * Tracks which URLs were successfully crawled</em>
<a name="79" href="#79">79</a>  <em>     */</em>
<a name="80" href="#80">80</a>      <strong>private</strong> Set&lt;String> successfullyCrawledUrls = <strong>new</strong> HashSet&lt;String>();
<a name="81" href="#81">81</a>  
<a name="82" href="#82">82</a>       <em>/**<em>*</em></em>
<a name="83" href="#83">83</a>  <em>     * Normal constructor - if encounter not-found seeds while loading</em>
<a name="84" href="#84">84</a>  <em>     * recoverLogFileName, will throw throw SeedUrlNotFoundException.</em>
<a name="85" href="#85">85</a>  <em>     * Use {@link #RecoveryLogMapper(String)} if you want to just log</em>
<a name="86" href="#86">86</a>  <em>     * such cases and keep going.  (Those should not happen if the</em>
<a name="87" href="#87">87</a>  <em>     * recover log is written correctly, but we see them in pratice.)</em>
<a name="88" href="#88">88</a>  <em>     * @param recoverLogFileName</em>
<a name="89" href="#89">89</a>  <em>     * @throws java.io.FileNotFoundException </em>
<a name="90" href="#90">90</a>  <em>     * @throws java.io.IOException </em>
<a name="91" href="#91">91</a>  <em>     * @throws SeedUrlNotFoundException </em>
<a name="92" href="#92">92</a>  <em>     */</em>
<a name="93" href="#93">93</a>      <strong>public</strong> <a href="../../../../org/archive/crawler/util/RecoveryLogMapper.html">RecoveryLogMapper</a>(String recoverLogFileName)
<a name="94" href="#94">94</a>      throws java.io.FileNotFoundException, java.io.IOException,
<a name="95" href="#95">95</a>              <a href="../../../../org/archive/crawler/util/SeedUrlNotFoundException.html">SeedUrlNotFoundException</a> {
<a name="96" href="#96">96</a>          load(recoverLogFileName);
<a name="97" href="#97">97</a>      }
<a name="98" href="#98">98</a>  
<a name="99" href="#99">99</a>      <em>/**<em>*</em></em>
<a name="100" href="#100">100</a> <em>     * Constructor to use if you want to allow not-found seeds, logging</em>
<a name="101" href="#101">101</a> <em>     * them to seedNotFoundLogFileName.  In contrast, {@link</em>
<a name="102" href="#102">102</a> <em>     * #RecoveryLogMapper(String)} will throw SeedUrlNotFoundException</em>
<a name="103" href="#103">103</a> <em>     * when a seed isn't found.</em>
<a name="104" href="#104">104</a> <em>     * @param recoverLogFileName</em>
<a name="105" href="#105">105</a> <em>     * @param seedNotFoundLogFileName</em>
<a name="106" href="#106">106</a> <em>     */</em>
<a name="107" href="#107">107</a>     <strong>public</strong> <a href="../../../../org/archive/crawler/util/RecoveryLogMapper.html">RecoveryLogMapper</a>(String recoverLogFileName,
<a name="108" href="#108">108</a>                              String seedNotFoundLogFileName)
<a name="109" href="#109">109</a>         throws java.io.FileNotFoundException, java.io.IOException,
<a name="110" href="#110">110</a>                <a href="../../../../org/archive/crawler/util/SeedUrlNotFoundException.html">SeedUrlNotFoundException</a> {
<a name="111" href="#111">111</a>         seedNotFoundPrintWriter = <strong>new</strong> PrintWriter(<strong>new</strong> FileOutputStream(
<a name="112" href="#112">112</a>                seedNotFoundLogFileName));
<a name="113" href="#113">113</a>         load(recoverLogFileName);
<a name="114" href="#114">114</a>     }
<a name="115" href="#115">115</a> 
<a name="116" href="#116">116</a>     <strong>protected</strong> <strong>void</strong> load(String recoverLogFileName)
<a name="117" href="#117">117</a>     throws java.io.FileNotFoundException, java.io.IOException,
<a name="118" href="#118">118</a>             <a href="../../../../org/archive/crawler/util/SeedUrlNotFoundException.html">SeedUrlNotFoundException</a> {
<a name="119" href="#119">119</a>         LineNumberReader reader = <strong>new</strong> LineNumberReader(RecoveryJournal.
<a name="120" href="#120">120</a>             getBufferedReader(<strong>new</strong> File(recoverLogFileName)));
<a name="121" href="#121">121</a>         String curLine = <strong>null</strong>;
<a name="122" href="#122">122</a>         <strong>while</strong> ((curLine = reader.readLine()) != <strong>null</strong>) {
<a name="123" href="#123">123</a>             <strong>if</strong> (curLine.length() == 0
<a name="124" href="#124">124</a>                     || curLine.charAt(0) != LOG_LINE_START_CHAR) {
<a name="125" href="#125">125</a>                 <strong>continue</strong>;
<a name="126" href="#126">126</a>             }
<a name="127" href="#127">127</a>             String args[] = curLine.split(<span class="string">"&#47;&#47;s+"</span>);
<a name="128" href="#128">128</a>             <strong>int</strong> curLineNumWords = args.length;
<a name="129" href="#129">129</a>             String firstUrl = args[1];
<a name="130" href="#130">130</a>             <em class="comment">// Ignore DNS log entries</em>
<a name="131" href="#131">131</a>             <strong>if</strong> (firstUrl.startsWith(<span class="string">"dns:"</span>)) {
<a name="132" href="#132">132</a>                 <strong>continue</strong>;
<a name="133" href="#133">133</a>             }
<a name="134" href="#134">134</a>             <strong>if</strong> (curLine.startsWith(RecoveryJournal.F_ADD)) {
<a name="135" href="#135">135</a>                 <em class="comment">// Seed URL</em>
<a name="136" href="#136">136</a>                 <strong>if</strong> (curLineNumWords == 2) {
<a name="137" href="#137">137</a>                     <strong>if</strong> (logger.isLoggable(Level.FINE)) {
<a name="138" href="#138">138</a>                         logger.fine(<span class="string">"F_ADD with 2 words --> seed URL ("</span> +
<a name="139" href="#139">139</a>                             firstUrl + <span class="string">")"</span>);
<a name="140" href="#140">140</a>                     }
<a name="141" href="#141">141</a>                     <em class="comment">// Add seed the first time we find it</em>
<a name="142" href="#142">142</a>                     <strong>if</strong> (seedUrlToDiscoveredUrlsMap.get(firstUrl) == <strong>null</strong>) {
<a name="143" href="#143">143</a>                         seedUrlToDiscoveredUrlsMap.put(firstUrl,
<a name="144" href="#144">144</a>                             <strong>new</strong> HashSet&lt;String>());
<a name="145" href="#145">145</a>                     }
<a name="146" href="#146">146</a>                 } <strong>else</strong> {
<a name="147" href="#147">147</a>                     <em class="comment">// URL found via an earlier seeded / discovered URL</em>
<a name="148" href="#148">148</a>                     <em class="comment">// Look for the seed from which firstUrlString came, so</em>
<a name="149" href="#149">149</a>                     <em class="comment">// we can collapse new URLString back to it</em>
<a name="150" href="#150">150</a>                     String viaUrl = args[curLineNumWords - 1];
<a name="151" href="#151">151</a>                     <strong>if</strong> (logger.isLoggable(Level.FINE)) {
<a name="152" href="#152">152</a>                         logger.fine(<span class="string">"F_ADD with 3+ words --> new URL "</span>
<a name="153" href="#153">153</a>                                 + firstUrl + <span class="string">" via URL "</span> + viaUrl);
<a name="154" href="#154">154</a>                     }
<a name="155" href="#155">155</a>                     String seedForFirstUrl =
<a name="156" href="#156">156</a>                         (String) crawledUrlToSeedMap.get(viaUrl);
<a name="157" href="#157">157</a>                     <em class="comment">// viaUrlString is a seed URL</em>
<a name="158" href="#158">158</a>                     <strong>if</strong> (seedForFirstUrl == <strong>null</strong>) {
<a name="159" href="#159">159</a>                         <strong>if</strong> (logger.isLoggable(Level.FINE)) {
<a name="160" href="#160">160</a>                             logger.fine(<span class="string">"\tvia URL is a seed"</span>);
<a name="161" href="#161">161</a>                         }
<a name="162" href="#162">162</a>                         crawledUrlToSeedMap.put(firstUrl, viaUrl);
<a name="163" href="#163">163</a>                         seedForFirstUrl = viaUrl;
<a name="164" href="#164">164</a>                     } <strong>else</strong> {
<a name="165" href="#165">165</a>                         <strong>if</strong> (logger.isLoggable(Level.FINE)) {
<a name="166" href="#166">166</a>                             logger.fine(<span class="string">"\tvia URL discovered via seed URL "</span> +
<a name="167" href="#167">167</a>                                 seedForFirstUrl);
<a name="168" href="#168">168</a>                         }
<a name="169" href="#169">169</a>                         <em class="comment">// Collapse</em>
<a name="170" href="#170">170</a>                         crawledUrlToSeedMap.put(firstUrl, seedForFirstUrl);
<a name="171" href="#171">171</a>                     }
<a name="172" href="#172">172</a>                     Set&lt;String> theSeedUrlList =
<a name="173" href="#173">173</a>                         seedUrlToDiscoveredUrlsMap.get(seedForFirstUrl);
<a name="174" href="#174">174</a>                         <strong>if</strong> (theSeedUrlList == <strong>null</strong>) {
<a name="175" href="#175">175</a>                         String message = <span class="string">"recover log "</span> +
<a name="176" href="#176">176</a>                                          recoverLogFileName + <span class="string">" at line "</span> +
<a name="177" href="#177">177</a>                                          reader.getLineNumber() +
<a name="178" href="#178">178</a>                                          <span class="string">" listed F+ URL ("</span> + viaUrl +
<a name="179" href="#179">179</a>                                          <span class="string">") for which found no seed list."</span>;
<a name="180" href="#180">180</a>                         <strong>if</strong> (seedNotFoundPrintWriter != <strong>null</strong>) {
<a name="181" href="#181">181</a>                             seedNotFoundPrintWriter.println(message);
<a name="182" href="#182">182</a>                         } <strong>else</strong> {
<a name="183" href="#183">183</a>                             <strong>throw</strong> <strong>new</strong> <a href="../../../../org/archive/crawler/util/SeedUrlNotFoundException.html">SeedUrlNotFoundException</a>(message);
<a name="184" href="#184">184</a>                         }
<a name="185" href="#185">185</a>                     } <strong>else</strong> {
<a name="186" href="#186">186</a>                         theSeedUrlList.add(firstUrl);
<a name="187" href="#187">187</a>                     }
<a name="188" href="#188">188</a>                 }
<a name="189" href="#189">189</a>             } <strong>else</strong> <strong>if</strong> (curLine.startsWith(RecoveryJournal.F_SUCCESS)) {
<a name="190" href="#190">190</a>                 <strong>if</strong> (logger.isLoggable(Level.FINE)) {
<a name="191" href="#191">191</a>                     logger.fine(<span class="string">"F_SUCCESS for URL "</span> + firstUrl);
<a name="192" href="#192">192</a>                 }
<a name="193" href="#193">193</a>                 successfullyCrawledUrls.add(firstUrl);
<a name="194" href="#194">194</a>             }
<a name="195" href="#195">195</a>         }
<a name="196" href="#196">196</a>         reader.close();
<a name="197" href="#197">197</a>         <strong>if</strong> (seedNotFoundPrintWriter != <strong>null</strong>) {
<a name="198" href="#198">198</a>             seedNotFoundPrintWriter.close();
<a name="199" href="#199">199</a>         }
<a name="200" href="#200">200</a>     }
<a name="201" href="#201">201</a> 
<a name="202" href="#202">202</a>     <em>/**<em>*</em></em>
<a name="203" href="#203">203</a> <em>     * Returns seed for urlString (null if seed not found).</em>
<a name="204" href="#204">204</a> <em>     * @param urlString</em>
<a name="205" href="#205">205</a> <em>     * @return Seed.</em>
<a name="206" href="#206">206</a> <em>     */</em>
<a name="207" href="#207">207</a>     <strong>public</strong> String getSeedForUrl(String urlString) {
<a name="208" href="#208">208</a>         <strong>return</strong> (seedUrlToDiscoveredUrlsMap.get(urlString) != <strong>null</strong>)?
<a name="209" href="#209">209</a>                 urlString: crawledUrlToSeedMap.get(urlString);
<a name="210" href="#210">210</a>     }
<a name="211" href="#211">211</a> 
<a name="212" href="#212">212</a>     <em>/**<em>*</em></em>
<a name="213" href="#213">213</a> <em>     * @return Returns the seedUrlToDiscoveredUrlsMap.</em>
<a name="214" href="#214">214</a> <em>     */</em>
<a name="215" href="#215">215</a>     <strong>public</strong> Map getSeedUrlToDiscoveredUrlsMap() {
<a name="216" href="#216">216</a>         <strong>return</strong> <strong>this</strong>.seedUrlToDiscoveredUrlsMap;
<a name="217" href="#217">217</a>     }
<a name="218" href="#218">218</a> 
<a name="219" href="#219">219</a>     <em>/**<em>*</em></em>
<a name="220" href="#220">220</a> <em>     * @return Returns the successfullyCrawledUrls.</em>
<a name="221" href="#221">221</a> <em>     */</em>
<a name="222" href="#222">222</a>     <strong>public</strong> Set getSuccessfullyCrawledUrls() {
<a name="223" href="#223">223</a>         <strong>return</strong> <strong>this</strong>.successfullyCrawledUrls;
<a name="224" href="#224">224</a>     }
<a name="225" href="#225">225</a> 
<a name="226" href="#226">226</a>     <em>/**<em>*</em></em>
<a name="227" href="#227">227</a> <em>     * @return Returns the logger.</em>
<a name="228" href="#228">228</a> <em>     */</em>
<a name="229" href="#229">229</a>     <strong>public</strong> <strong>static</strong> Logger getLogger() {
<a name="230" href="#230">230</a>         <strong>return</strong> logger;
<a name="231" href="#231">231</a>     }
<a name="232" href="#232">232</a> 
<a name="233" href="#233">233</a>     <strong>private</strong> <strong>class</strong> SuccessfullyCrawledURLsIterator
<a name="234" href="#234">234</a>     implements Iterator&lt;String> {
<a name="235" href="#235">235</a>         <strong>private</strong> String nextValue = <strong>null</strong>;
<a name="236" href="#236">236</a>         <strong>private</strong> Iterator discoveredUrlsIterator;
<a name="237" href="#237">237</a> 
<a name="238" href="#238">238</a>         <strong>public</strong> SuccessfullyCrawledURLsIterator(String seedUrlString)
<a name="239" href="#239">239</a>         throws <a href="../../../../org/archive/crawler/util/SeedUrlNotFoundException.html">SeedUrlNotFoundException</a> {
<a name="240" href="#240">240</a>             Set discoveredUrlList =
<a name="241" href="#241">241</a>                 (Set)getSeedUrlToDiscoveredUrlsMap().get(seedUrlString);
<a name="242" href="#242">242</a>             <strong>if</strong> (discoveredUrlList == <strong>null</strong>) {
<a name="243" href="#243">243</a>                 <strong>throw</strong> <strong>new</strong> <a href="../../../../org/archive/crawler/util/SeedUrlNotFoundException.html">SeedUrlNotFoundException</a>(<span class="string">"Seed URL "</span> +
<a name="244" href="#244">244</a>                     seedUrlString + <span class="string">"  not found in seed list"</span>);
<a name="245" href="#245">245</a>             }
<a name="246" href="#246">246</a>             discoveredUrlsIterator = discoveredUrlList.iterator();
<a name="247" href="#247">247</a>         }
<a name="248" href="#248">248</a> 
<a name="249" href="#249">249</a>         <em>/**<em>*</em></em>
<a name="250" href="#250">250</a> <em>         * Idempotent method (because of null check on nextValue).</em>
<a name="251" href="#251">251</a> <em>         */</em>
<a name="252" href="#252">252</a>         <strong>private</strong> <strong>void</strong> populateNextValue() {
<a name="253" href="#253">253</a>             <strong>while</strong> (nextValue == <strong>null</strong> &amp; discoveredUrlsIterator.hasNext()) {
<a name="254" href="#254">254</a>                 String curDiscoveredUrl =
<a name="255" href="#255">255</a>                     (String)discoveredUrlsIterator.next();
<a name="256" href="#256">256</a>                 <strong>boolean</strong> succCrawled = getSuccessfullyCrawledUrls().
<a name="257" href="#257">257</a>                     contains(curDiscoveredUrl);
<a name="258" href="#258">258</a>                 <strong>if</strong> (getLogger().isLoggable(Level.FINE)) {
<a name="259" href="#259">259</a>                     getLogger().fine(<span class="string">"populateNextValue: curDiscoveredUrl="</span> +
<a name="260" href="#260">260</a>                             curDiscoveredUrl + <span class="string">", succCrawled="</span> +
<a name="261" href="#261">261</a>                             succCrawled);
<a name="262" href="#262">262</a>                 }
<a name="263" href="#263">263</a>                 <strong>if</strong> (succCrawled)
<a name="264" href="#264">264</a>                     nextValue = curDiscoveredUrl;
<a name="265" href="#265">265</a>             }
<a name="266" href="#266">266</a>         }
<a name="267" href="#267">267</a> 
<a name="268" href="#268">268</a>         <strong>public</strong> <strong>boolean</strong> hasNext() {
<a name="269" href="#269">269</a>             populateNextValue();
<a name="270" href="#270">270</a>             <strong>return</strong> (nextValue != <strong>null</strong>);
<a name="271" href="#271">271</a>         }
<a name="272" href="#272">272</a> 
<a name="273" href="#273">273</a>         <strong>public</strong> String next() {
<a name="274" href="#274">274</a>             populateNextValue();
<a name="275" href="#275">275</a>             String returnValue = nextValue;
<a name="276" href="#276">276</a>             nextValue = <strong>null</strong>;
<a name="277" href="#277">277</a>             <strong>return</strong> <strong>return</strong>Value;
<a name="278" href="#278">278</a>         }
<a name="279" href="#279">279</a> 
<a name="280" href="#280">280</a>         <em>/**<em>*</em></em>
<a name="281" href="#281">281</a> <em>         * Remove operation is unsupported in this Iterator</em>
<a name="282" href="#282">282</a> <em>         * (will throw UnsupportedOperationException if called).</em>
<a name="283" href="#283">283</a> <em>         */</em>
<a name="284" href="#284">284</a>         <strong>public</strong> <strong>void</strong> remove() {
<a name="285" href="#285">285</a>             <strong>throw</strong> <strong>new</strong> UnsupportedOperationException(
<a name="286" href="#286">286</a>                 <span class="string">"SuccessfullyCrawledURLsIterator.remove: not supported."</span>);
<a name="287" href="#287">287</a>         }
<a name="288" href="#288">288</a>     }
<a name="289" href="#289">289</a> 
<a name="290" href="#290">290</a>     <strong>public</strong> Iterator&lt;String> getIteratorOfURLsSuccessfullyCrawledFromSeedUrl(
<a name="291" href="#291">291</a>             String seedUrlString) throws SeedUrlNotFoundException {
<a name="292" href="#292">292</a>         <strong>return</strong> <strong>new</strong> SuccessfullyCrawledURLsIterator(seedUrlString);
<a name="293" href="#293">293</a>     }
<a name="294" href="#294">294</a> 
<a name="295" href="#295">295</a>     <strong>public</strong> Collection&lt;String> getSeedCollection() {
<a name="296" href="#296">296</a>         <strong>return</strong> seedUrlToDiscoveredUrlsMap.keySet();
<a name="297" href="#297">297</a>     }
<a name="298" href="#298">298</a> 
<a name="299" href="#299">299</a>     <strong>public</strong> <strong>static</strong> <strong>void</strong> main(String args[]) {
<a name="300" href="#300">300</a>         <strong>if</strong> (args.length &lt; 1) {
<a name="301" href="#301">301</a>             System.out.println(<span class="string">"Usage: RecoveryLogMapper recoverLogFileName"</span>);
<a name="302" href="#302">302</a>             Runtime.getRuntime().exit(-1);
<a name="303" href="#303">303</a>         }
<a name="304" href="#304">304</a>         String recoverLogFileName = args[0];
<a name="305" href="#305">305</a>         <strong>try</strong> {
<a name="306" href="#306">306</a>             <a href="../../../../org/archive/crawler/util/RecoveryLogMapper.html">RecoveryLogMapper</a> myRecoveryLogMapper =
<a name="307" href="#307">307</a>                 <strong>new</strong> <a href="../../../../org/archive/crawler/util/RecoveryLogMapper.html">RecoveryLogMapper</a>(recoverLogFileName);
<a name="308" href="#308">308</a>             <strong>for</strong> (String curSeedUrl: myRecoveryLogMapper.getSeedCollection()) {
<a name="309" href="#309">309</a>                 System.out.println(<span class="string">"URLs successfully crawled from seed URL "</span>
<a name="310" href="#310">310</a>                     + curSeedUrl);
<a name="311" href="#311">311</a>                 Iterator iteratorOfUrlsCrawledFromSeedUrl =
<a name="312" href="#312">312</a>                     myRecoveryLogMapper.
<a name="313" href="#313">313</a>                         getIteratorOfURLsSuccessfullyCrawledFromSeedUrl(
<a name="314" href="#314">314</a>                             curSeedUrl);
<a name="315" href="#315">315</a>                 <strong>while</strong> (iteratorOfUrlsCrawledFromSeedUrl.hasNext()) {
<a name="316" href="#316">316</a>                     String curCrawledUrlString =
<a name="317" href="#317">317</a>                         (String)iteratorOfUrlsCrawledFromSeedUrl.next();
<a name="318" href="#318">318</a>                     System.out.println(<span class="string">"    -> "</span> + curCrawledUrlString);
<a name="319" href="#319">319</a>                 }
<a name="320" href="#320">320</a>             }
<a name="321" href="#321">321</a>         } <strong>catch</strong> (Exception e) {
<a name="322" href="#322">322</a>             e.printStackTrace();
<a name="323" href="#323">323</a>         }
<a name="324" href="#324">324</a>     }
<a name="325" href="#325">325</a> }
</pre>
<hr/><div id="footer">This page was automatically generated by <a href="http://maven.apache.org/">Maven</a></div></body>
</html>

